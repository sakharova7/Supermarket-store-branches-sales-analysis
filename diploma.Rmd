---
title: "ВКР. Сахарова П.А., КББО-01-20"
output:
  html_document:
    df_print: paged
  pdf_document: default
---
## Описание данных  
За основу был взят набор данных с источника Kaggle "Supermarket store branches sales analysis".  
Таблица содержит следующие колонки:  
* Store.ID (идентификатор магазина);  
* Store_Area (площадь магазина в квадратных ярдах, числовая переменная);  
* Items_Available (число доступных различных товаров, числовая переменная);  
* Daily_Customer_Count (среднее число посетителей в день, числовая переменная);  
* Store_Sales (продажи магазина в долларах США, числовая переменная).    

## 1. Чтение данных. Добавление переменных

Сохраним датасет в переменную df и посмотрим на первые 5 строк.
```{r echo=F}
df<-read.csv("Stores.csv")
head(df,5)
```
Не хватает категориальных переменных. Создадим их сами.  
Пусть Self_Service - бинарная переменная, которая разбивает супермаркеты на два класса: те, в которых есть кассы самообслуживания (Yes) и те, в которых их нет (No).  
Пусть Organisation_Level - категориальная переменная, классифицирующая супермаркеты по уровню организации: International (располагаются в разных странах), Federal (располагаются в разных субъектах одной страны), Regional (располагаются в разных регионах одного субъекта одной страны), Local (располагаются в пределах одного города). 

```{r echo=F}
set.seed(7)
df$Self_Service <- sample(c('Yes', 'No'), nrow(df), replace=TRUE)
df$Organisation_Level <- sample(c('International', 'Federal', 'Regional', 'Local'), nrow(df), replace=TRUE)
head(df,10)
```


Добавим пропуски в любые 25 строк по переменной Store_Area и в любые 10 строк по переменной Daily_Customer_Count. Выведем наблюдения, в которых содержатся пропущенные значения.
```{r echo=F}
vector_1<-sample(1:nrow(df), 25)
vector_2<-sample(1:nrow(df),10)
df$Store_Area[c(vector_1)] <- NA
df$Daily_Customer_Count[c(vector_2)]<- NA
df[is.na(df$Store_Area)|is.na(df$Daily_Customer_Count),]
```
Требования задания соблюдены. Приступаем к EDA-анализу.

## 1. EDA-анализ

### 1.1 Структура данных. Преобразование категорий в факторы

Выведем общую информацию о наших данных.
```{r echo=F}
summary(df)
```
Как видим, в таблице приведены данные по `r nrow(df)` магазинам. Все колонки, за исключением двух последних, имеют целочисленный тип. Для корректной работы статистических тестов сделаем категориальные переменные факторными.
```{r echo=F}
df$Self_Service<-as.factor(df$Self_Service)
df$Organisation_Level<-as.factor(df$Organisation_Level)
str(df)
```
### 1.2 Поиск выбросов и обработка пропущенных значений

Из таблицы выше (summary(df)) следует, что разброс значений по переменной Store_Area не очень велик: площадь магазина лежит в пределах от 775 до 2229 кв. ярдов. 
Посмотрим на распределение значений площади.
```{r echo=F,warning=FALSE}
library(ggplot2)
ggplot(df, aes(x=Store_Area))+geom_histogram(bins=20, color="black", fill="yellow4", )
```

Распределение напоминает нормальное. Проверим формально критерием Шапиро-Уилка.
```{r echo=F}
shapiro.test(df$Store_Area)
```
p-value > 0.05, то есть оснований отвергнуть нулевую гипотезу о соответствии распределения нормальному у нас нет.  
Судя по гистограмме, выбросов нет или их немного. Убедимся в этом, построив боксплот.
```{r echo=F, warning=F}
ggplot(df,aes(y=Store_Area))+geom_boxplot()
```

Всё же они есть. Посмотрим на эти строки.
```{r echo=F}
df[(df$Store_Area<=800|df$Store_Area>=2200)&(is.na(df$Store_Area)==FALSE),]
```
Нельзя сказать, что значения сильно выбиваются из общего ряда (другое дело - встретить площадь 1 кв. ярд или, наоборот, 100 000 кв. ярдов), поэтому оставим их.  
Мы приняли решение, что выбросов нет. Следовательно, характеристикой столбца вполне послужит среднее значение. Пропущенные значения переменной Store_Area заменим средним значением этого столбца (рассчитанным без учета пропусков).
```{r echo=F}
df$Store_Area<-replace(df$Store_Area,is.na(df$Store_Area)==T, mean(df$Store_Area, na.rm=T, digits=0))
summary(df)
```
Пропусков по переменной Store_Area больше нет.
Посмотрим на распределение переменной Daily_Customer_Count.
```{r echo=F,warning=FALSE}
ggplot(df, aes(x=Daily_Customer_Count))+geom_histogram(bins=20, color="black", fill="darkgreen", )
```

Распределение также напоминает нормальное. 
```{r echo=F}
shapiro.test(df$Daily_Customer_Count)
```
Поищем выбросы.

```{r echo=F, warning=F}
ggplot(df,aes(y=Daily_Customer_Count))+geom_boxplot()
```

Выбросов немного, и значения, на мой взгляд, не противоречат смыслу.    
В этот раз с пропущенными значениями поступим иначе: просто удалим строки (их всего 10, по сравнению с размером датасета - очень маленькое число).  
Заодно удалим столбец Store.ID - для анализа он бесполезен.
```{r echo=F, warning=FALSE}
library(tidyr)
df <- df %>% drop_na()
df <- subset(df, select = - Store.ID)
summary(df)
```
Пропущенных значений больше нет.  

Посмотрим на распределение переменной Items_Available.
```{r echo=F,warning=FALSE}
ggplot(df, aes(x=Items_Available))+geom_histogram(bins=20, color="black", fill="orange2", )
```
```{r echo=F}
shapiro.test(df$Items_Available)
```

## 2. Визуализация и поиск зависимостей  

Посмотрим, насколько отличается распределение продаж в зависимости от типа организации супермаркета.
```{r echo=F, warning=FALSE}
ggplot(df, aes(x=Store_Sales,fill=Organisation_Level))+
geom_histogram(color="black", bins=15)+
facet_grid(df$Organisation_Level)+theme_light()

```

Похоже, распределение продаж не зависит от уровня организации магазина (следует помнить, что категории были присвоены случайным образом).
Посмотрим, влияет ли наличие касс самообслуживания на количество посетителей магазина.
```{r echo=F, message=F}
ggplot(df,aes(y=Daily_Customer_Count, x=Self_Service))+
geom_boxplot()
```

Разницы почти нет.  
Посмотрим на распределение переменной "Продажи".
```{r echo=F}
qqnorm(df$Store_Sales)
qqline(df$Store_Sales)
```

"Хвосты" qq-plot почти лежат на биссектрисе, не исключено, что распределение нормальное.
```{r echo=F, warning=F}
shapiro.test(df$Store_Sales)
ks.test(df$Store_Sales,"pnorm")
```
Предположение оказалось неверным. Распределение Store_Sales отличается от нормального.
Попробуем прологарифмировать переменную, чтобы "подправить" распределение.
```{r echo=F}
shapiro.test(log(df$Store_Sales))
```
Не помогло. Попробуем извлечь корень из исходных данных.
```{r echo=F}
shapiro.test(sqrt(df$Store_Sales))
```
Исправить распределение не удалось. 

Попробуем поискать зависимость между переменными.

```{r echo=F}
df_numeric<-df[,c(1,2,3,4)]
psych::pairs.panels(df_numeric)
```

Линейно связаны между собой только ассортимент магазина и его площадь, что довольно логично.
```{r echo=F}
ggplot(df,aes(x=Items_Available, y=Store_Area))+geom_point()
```

Сложно выявить какой-то тренд относительно переменной Store_Sales.

```{r echo=F, warning=F}
ggplot(df,aes(x=Daily_Customer_Count, y=Store_Sales, color=Self_Service))+geom_point()
```

Наличие касс самообслуживания тоже не оказало влияния на продажи и число посетителей.  
Посмотрим ещё раз на коэффициенты корреляции между переменными.
```{r echo=F, warning=F, message=F}
library(psych)
corr_matrix<-corr.test(df_numeric)
corr_matrix$r
```
Сильная корреляция присутствует только между переменными Store_Area и Items_Available.
Проверим значимость коэффициентов.
```{r echo=F}
corr_matrix$p
```
```{r echo=F, warning=F}
#install.packages("xtable")
library(xtable)
my_table<-xtable(corr_matrix$r)
print(my_table,type="html", file="my_table.html")
```

Значимыми оказались только коэффициенты между Store_Area и Items_Available, Store_Area и Store_Sales, Items_Available и Store_Sales.

Сначала я собиралась исследовать зависимость выручки супермаркетов от посещаемости, ассортимента и площади магазина. Однако, поскольку линейной взаимосвязи между ними не наблюдается, лучше посмотреть, какие факторы влияют на площадь магазина.  

## 3. Модели линейной регрессии

### 3.1 Разбивка датасета. Полная и оптимальная модели

Сначала отберём данные для прогнозирования: последние 20 строк датасета уберём из обучающей выборки и оставим их для контрольной проверки.  
```{r echo=F}
df_predict <- tail(df,20)
df_train <- head(df,nrow(df)-20)
```

Сперва построим полную модель, включив в неё все факторы.

```{r echo=F}
model_1<-lm(Store_Area~., df_train)
summary(model_1)
```

Значение p-value говорит о значимости только числа товаров, что было понятно ещё на этапе корреляционного анализа. О низкой значимости Daily_Customer_Count и Store_Sales свидетельствуют самые высокие значения p-value и низкие значения коэффициентов. В данном случае площадь  полностью описывается количеством разных товаров в ассортименте супермаркета.
```{r echo=F}
model_2<-lm(Store_Area~Items_Available, df_train)
summary(model_2)
```
Константа и Items_Available значимы.  
Значение Adjusted R-squared совпадает в обеих моделях, что позволяет говорить о их взаимозаменяемости. Убедимся в этом с помощью дисперсионного анализа.
```{r echo=F}
anova(model_1, model_2)
```

Значение p-value превышает 0.05, поэтому мы не отклоняем нулевую гипотезу о том, что модель с одним признаком работает не хуже полной модели.
Покажем это с помощью пошагового исключения предикторов из полной модели.
```{r echo=F}
model_3<-step(model_1,direction="backward")
summary(model_3)
```
Как видим, алгоритм пошагового исключения также оставил только один фактор.  Критерий Акаике принимает наименьшее значение в этом случае, что свидетельствует об оптимальности последней модели.  

### 3.2 Предсказание значений Store_Area

Попробуем предсказать значения колонки "Площадь" в df_predict с помощью второй модели.
```{r echo=F}
df_predict$Predicted_Store_Area<-predict(model_2,df_predict)
df_predict$Difference<-df_predict$Store_Area-df_predict$Predicted_Store_Area
df_predict
```

Рассчитаем среднеквадратичную ошибку (RMSE) для второй модели.
```{r echo=F}
rmse<-sqrt(sum(df_predict$Difference^2))
rmse
```
Сравним с ошибкой полной модели.
```{r echo=F}
df_predict$Full_Predicted_Store_Area<-predict(model_1,df_predict)
df_predict$Full_Difference<-df_predict$Store_Area-df_predict$Full_Predicted_Store_Area
rmse_full<-sqrt(sum(df_predict$Full_Difference^2))
rmse_full
```
Ошибка модели, учитывающей все факторы, выше, чем у модели с одним фактором. 

### 3.3 Визуальная диагностика моделей

Построим диагностические диаграммы двух моделей.

```{r echo=F}
par(mfrow = c(2, 2))
plot(model_1, main='Full model')
plot(model_2, main='Best model')
```

Residuals vs Fitted: в обеих моделях линия расположена горизонтально, то есть линейность модели соблюдается.  
Q-Q Residuals: в обеих моделях распределение остатков похоже на нормальное.  
Scale-Location: в обоих случаях линия горизонтальна, что говорит о равенстве дисперсий и, следовательно, гомоскедастичности.  
Residuals vs Leverage: присутствуют влиятельные наблюдения.  
Наши предположения необходимо проверить с помощью стат. тестов.

### 3.4 Статистическая диагностика моделей (проверка соблюдения предпосылок)

1. Мультиколлинеарность  
Искать зависимости между предикторами придется только в полной модели.
```{r echo=F, warning=F, message=F}
library(car)
vif(model_1)
```
Все значения VIF едва превышают 1, что говорит об отсутствии корреляции между признаками. Значит, модель не является избыточной с точки зрения повторения скоррелированных признаков.  

2. Линейность моделей  
Проверим с помощью теста Рамсея, все ли степени присутствуют в моделях.
```{r echo=F, message=F, warning=F}
library(lmtest)
resettest(model_1)
resettest(model_2)

```
p-value в обоих случаях превышает 0.05, значит, нулевую гипотезу ("Модель построена корректно, вводить другие степени не требуется") отклонить нет оснований, и наши модели линейны.

3. Проверка на гетероскедастичность  
Проверим двумя тестами:   
- нулевая гипотеза теста Бройша-Пагана: гетероскедастичность отсутствует;  
- нулевая гипотеза теста Голдфелда-Квандта: гетероскедастичность отсутствует.
```{r echo=F}
bptest(model_1)
gqtest(model_1)

bptest(model_2)
gqtest(model_2)
```
p-value превышает 0.05, оснований для отвергания нулевой гипотезы нет. Следовательно, разброс остатков обеих моделей одинаков.

4. Влиятельные наблюдения  
Используем метрику расстояний Кука для поиска выбросов. Выведем максимальное значение метрики для второй модели.
```{r echo=F}
cooks.distance(model_2)[which.max(cooks.distance(model_2))]
```
Наблюдение 406 похоже на выброс. 
Можно по-разному выбирать порог для идентификации выбросов.  
Наблюдение оказывает большое влияние на предсказания модели, если:  
1) расстояние Кука больше 1 или  
2) расстояние Кука больше 4/(N-k-1), где N - количество наблюдений в обучающей выборке, k - количество предикторов.  
Будем использовать второй подход для определения порога.

```{r echo=F}
plot(cooks.distance(model_2),type="b",pch=20,col="green3")
N = nrow(df_train)
k = 1
cutoff = 4/ (N-k-1)
abline(h=cutoff,lty=2, col="blue3")
```

Видим, что у нас довольно много выбросов.
```{r echo=F}
cooks.distance(model_2)[cooks.distance(model_2)> 4/(N-k-1)]
```
16 сомнительных наблюдений. Посмотрим, что будет, если исключить их из набора данных.
```{r echo=F}
bad_vector<-which(cooks.distance(model_2)> 4/(N-k-1))
model_2_fixed<-lm(Store_Area~Items_Available, 
                  df_train[-bad_vector,])
plot(model_2_fixed)
summary(model_2_fixed)
```
В результате исключения строк, содержащих выбросы, мы добились отсутствия наблюдений за пунктирными границами, которые влияют на модель, и даже немного повысили Adjusted R-squared, т.е. без выбросов вторая модель лучше объясняет дисперсию переменной Store_Area.  
Посмотрим на ошибку предсказания и сравним с предыдущими.
```{r echo=F}
df_predict$Best_Predicted_Store_Area<-predict(model_2_fixed,df_predict)
df_predict$Best_Difference<-df_predict$Store_Area-df_predict$Best_Predicted_Store_Area
rmse_best<-sqrt(sum(df_predict$Best_Difference^2))
sprintf("RMSE of fixed second model: %f", rmse_best)
sprintf("RMSE of full model: %f", rmse_full)
sprintf("RMSE of second model: %f", rmse)

```
Среднеквадратичная ошибка уменьшилась.
Вероятно, у полной модели расстояние Кука тоже превышает дозволенное в выявленных ранее наблюдениях.
```{r echo=F}
k_1<-5
cooks.distance(model_1)[cooks.distance(model_2)> 4/(N-k_1-1)]
```
Наблюдения те же самые. Пересчитаем полную модель (без выбросов).
```{r echo=F}
model_1_fixed<-lm(Store_Area~., 
                  df_train[-bad_vector,])
plot(model_1_fixed)
summary(model_1_fixed)
```
5. Распределение остатков

 Поскольку выборка большая, будем использовать тест Колмогорова-Смирнова.
```{r echo=F, warning=F}
hist(residuals(model_1_fixed))
hist(residuals(model_2_fixed))
ks.test(residuals(model_1_fixed), "pnorm")
ks.test(residuals(model_2_fixed), "pnorm")
```
Распределение остатков не является нормальным.

## 4. Факторные переменные

Проверим с помощью стат. тестов, влияет ли принадлежность магазина к категориям (Organisation_Level и Self_Service) на другие показатели.
Поскольку выборка большая (более 800 наблюдений), фактом отклонения распределения переменной Store_Sales можно пренебречь. 
Посмотрим, как влияют эти два фактора на остальные переменные с помощью дисперсионного анализа.
```{r echo=F}
fit_1<- aov(data = df, Items_Available ~ Organisation_Level * Self_Service)
summary(fit_1)
```

```{r echo=F}
fit_2<- aov(data = df, Store_Sales ~ Organisation_Level * Self_Service)
summary(fit_2)
```
```{r echo=F}
fit_3<- aov(data = df, Daily_Customer_Count ~ Organisation_Level * Self_Service)
summary(fit_3)
```
```{r echo=F}
fit_4<- aov(data = df, Store_Area ~ Organisation_Level * Self_Service)
summary(fit_4)
```
Обнаружилось, что оба фактора, а также их взаимодействие не влияют ни на одну из характеристик супермаркета.

## Выводы

***В ходе исследования выполнены следующие задачи***: 

  + был проведен исследовательский анализ данных (создание и обработка пропущенных значений, поиск выбросов методом "ящика с усами", преобразование строковых данных в факторные);  
  + получены визуализации распределения переменных, проведены тесты на нормальность методом Шапиро-Уилка;  
  + показано, что категориальные переменные не влияют на другие показатели;  
  + исследованы линейные зависимости между переменными с помощью скаттероплотов и корреляционной матрицы. Отобрана зависимая переменная;  
  + построены две модели, выполнены предсказания значений зависимой переменной;  
  + выполнен сравнительный анализ эффективности двух моделей;  
  + проведена проверка выполнения предпосылок для построения уравнения линейной регрессии. Удалены выбросы и выполнен перерасчёт моделей. В результате удаления выбросов удалось увеличить процент объясненной диспрерсии. 

Фактор, определяющий площадь супермаркета - ассортимент товаров. Между этими параметрами сильнейшая положительная корреляционная связь.


```{r echo=F, message=F, warning=F, results='hide'}
library(memisc)
my_table_2<-mtable(model_1, model_2)
```




